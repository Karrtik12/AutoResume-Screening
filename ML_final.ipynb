{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# 0. Imports & config\n",
        "# =====================================================\n",
        "\n",
        "# !pip install gender-guesser scikit-learn pandas numpy matplotlib\n",
        "\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import LinearSVC, SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "import gender_guesser.detector as gender\n",
        "\n",
        "RANDOM_STATE = 42\n",
        "np.random.seed(RANDOM_STATE)\n",
        "plt.rcParams[\"figure.dpi\"] = 120\n",
        "\n",
        "# Output directory\n",
        "output_dir = \"./data/ml_pipeline_outputs\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Shape: (9544, 38)\n",
            "Columns: ['name', 'address', 'career_objective', 'skills', 'educational_institution_name', 'degree_names', 'passing_years', 'educational_results', 'result_types', 'major_field_of_studies', 'professional_company_names', 'company_urls', 'start_dates', 'end_dates', 'years_of_experience', 'related_skils_in_job', 'positions', 'locations', 'responsibilities', 'extra_curricular_activity_types', 'extra_curricular_organization_names', 'extra_curricular_organization_links', 'role_positions', 'languages', 'proficiency_levels', 'certification_providers', 'certification_skills', 'online_links', 'issue_dates', 'expiry_dates', 'job_position_name', 'educationaL_requirements', 'experiencere_requirement', 'age_requirement', 'responsibilities.1', 'skills_required', 'matched_score', 'shortlist']\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "      <th>career_objective</th>\n",
              "      <th>skills</th>\n",
              "      <th>educational_institution_name</th>\n",
              "      <th>degree_names</th>\n",
              "      <th>passing_years</th>\n",
              "      <th>educational_results</th>\n",
              "      <th>result_types</th>\n",
              "      <th>major_field_of_studies</th>\n",
              "      <th>...</th>\n",
              "      <th>issue_dates</th>\n",
              "      <th>expiry_dates</th>\n",
              "      <th>job_position_name</th>\n",
              "      <th>educationaL_requirements</th>\n",
              "      <th>experiencere_requirement</th>\n",
              "      <th>age_requirement</th>\n",
              "      <th>responsibilities.1</th>\n",
              "      <th>skills_required</th>\n",
              "      <th>matched_score</th>\n",
              "      <th>shortlist</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Greta</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Big data analytics working and database wareho...</td>\n",
              "      <td>['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...</td>\n",
              "      <td>['The Amity School of Engineering &amp; Technology...</td>\n",
              "      <td>['B.Tech']</td>\n",
              "      <td>['2019']</td>\n",
              "      <td>['N/A']</td>\n",
              "      <td>[None]</td>\n",
              "      <td>['Electronics']</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Senior Software Engineer</td>\n",
              "      <td>B.Sc in Computer Science &amp; Engineering from a ...</td>\n",
              "      <td>At least 1 year</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Technical Support\\nTroubleshooting\\nCollaborat...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.850000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kamau</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Fresher looking to join as a data analyst and ...</td>\n",
              "      <td>['Data Analysis', 'Data Analytics', 'Business ...</td>\n",
              "      <td>['Delhi University - Hansraj College', 'Delhi ...</td>\n",
              "      <td>['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']</td>\n",
              "      <td>['2015', '2018']</td>\n",
              "      <td>['N/A', 'N/A']</td>\n",
              "      <td>['N/A', 'N/A']</td>\n",
              "      <td>['Mathematics', 'Statistics']</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Machine Learning (ML) Engineer</td>\n",
              "      <td>M.Sc in Computer Science &amp; Engineering or in a...</td>\n",
              "      <td>At least 5 year(s)</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Machine Learning Leadership\\nCross-Functional ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.750000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Patricia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>['Software Development', 'Machine Learning', '...</td>\n",
              "      <td>['Birla Institute of Technology (BIT), Ranchi']</td>\n",
              "      <td>['B.Tech']</td>\n",
              "      <td>['2018']</td>\n",
              "      <td>['N/A']</td>\n",
              "      <td>['N/A']</td>\n",
              "      <td>['Electronics/Telecommunication']</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Executive/ Senior Executive- Trade Marketing, ...</td>\n",
              "      <td>Master of Business Administration (MBA)</td>\n",
              "      <td>At least 3 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Trade Marketing Executive\\nBrand Visibility, S...</td>\n",
              "      <td>Brand Promotion\\nCampaign Management\\nField Su...</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elena</td>\n",
              "      <td>NaN</td>\n",
              "      <td>To obtain a position in a fast-paced business ...</td>\n",
              "      <td>['accounts payables', 'accounts receivables', ...</td>\n",
              "      <td>['Martinez Adult Education, Business Training ...</td>\n",
              "      <td>['Computer Applications Specialist Certificate...</td>\n",
              "      <td>['2008']</td>\n",
              "      <td>[None]</td>\n",
              "      <td>[None]</td>\n",
              "      <td>['Computer Applications']</td>\n",
              "      <td>...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Business Development Executive</td>\n",
              "      <td>Bachelor/Honors</td>\n",
              "      <td>1 to 3 years</td>\n",
              "      <td>Age 22 to 30 years</td>\n",
              "      <td>Apparel Sourcing\\nQuality Garment Sourcing\\nRe...</td>\n",
              "      <td>Fast typing skill\\nIELTSInternet browsing &amp; on...</td>\n",
              "      <td>0.760000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Zara</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Professional accountant with an outstanding wo...</td>\n",
              "      <td>['Analytical reasoning', 'Compliance testing k...</td>\n",
              "      <td>['Kent State University']</td>\n",
              "      <td>['Bachelor of Business Administration']</td>\n",
              "      <td>[None]</td>\n",
              "      <td>['3.84']</td>\n",
              "      <td>[None]</td>\n",
              "      <td>['Accounting']</td>\n",
              "      <td>...</td>\n",
              "      <td>[None]</td>\n",
              "      <td>['February 15, 2021']</td>\n",
              "      <td>Senior iOS Engineer</td>\n",
              "      <td>Bachelor of Science (BSc) in Computer Science</td>\n",
              "      <td>At least 4 years</td>\n",
              "      <td>NaN</td>\n",
              "      <td>iOS Lifecycle\\nRequirement Analysis\\nNative Fr...</td>\n",
              "      <td>iOS\\niOS App Developer\\niOS Application Develo...</td>\n",
              "      <td>0.650000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 38 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       name address                                   career_objective  \\\n",
              "0     Greta     NaN  Big data analytics working and database wareho...   \n",
              "1     Kamau     NaN  Fresher looking to join as a data analyst and ...   \n",
              "2  Patricia     NaN                                                NaN   \n",
              "3     Elena     NaN  To obtain a position in a fast-paced business ...   \n",
              "4      Zara     NaN  Professional accountant with an outstanding wo...   \n",
              "\n",
              "                                              skills  \\\n",
              "0  ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...   \n",
              "1  ['Data Analysis', 'Data Analytics', 'Business ...   \n",
              "2  ['Software Development', 'Machine Learning', '...   \n",
              "3  ['accounts payables', 'accounts receivables', ...   \n",
              "4  ['Analytical reasoning', 'Compliance testing k...   \n",
              "\n",
              "                        educational_institution_name  \\\n",
              "0  ['The Amity School of Engineering & Technology...   \n",
              "1  ['Delhi University - Hansraj College', 'Delhi ...   \n",
              "2    ['Birla Institute of Technology (BIT), Ranchi']   \n",
              "3  ['Martinez Adult Education, Business Training ...   \n",
              "4                          ['Kent State University']   \n",
              "\n",
              "                                        degree_names     passing_years  \\\n",
              "0                                         ['B.Tech']          ['2019']   \n",
              "1    ['B.Sc (Maths)', 'M.Sc (Science) (Statistics)']  ['2015', '2018']   \n",
              "2                                         ['B.Tech']          ['2018']   \n",
              "3  ['Computer Applications Specialist Certificate...          ['2008']   \n",
              "4            ['Bachelor of Business Administration']            [None]   \n",
              "\n",
              "  educational_results    result_types             major_field_of_studies  ...  \\\n",
              "0             ['N/A']          [None]                    ['Electronics']  ...   \n",
              "1      ['N/A', 'N/A']  ['N/A', 'N/A']      ['Mathematics', 'Statistics']  ...   \n",
              "2             ['N/A']         ['N/A']  ['Electronics/Telecommunication']  ...   \n",
              "3              [None]          [None]          ['Computer Applications']  ...   \n",
              "4            ['3.84']          [None]                     ['Accounting']  ...   \n",
              "\n",
              "  issue_dates           expiry_dates  \\\n",
              "0         NaN                    NaN   \n",
              "1         NaN                    NaN   \n",
              "2         NaN                    NaN   \n",
              "3         NaN                    NaN   \n",
              "4      [None]  ['February 15, 2021']   \n",
              "\n",
              "                                   job_position_name  \\\n",
              "0                           Senior Software Engineer   \n",
              "1                     Machine Learning (ML) Engineer   \n",
              "2  Executive/ Senior Executive- Trade Marketing, ...   \n",
              "3                     Business Development Executive   \n",
              "4                                Senior iOS Engineer   \n",
              "\n",
              "                            educationaL_requirements  \\\n",
              "0  B.Sc in Computer Science & Engineering from a ...   \n",
              "1  M.Sc in Computer Science & Engineering or in a...   \n",
              "2            Master of Business Administration (MBA)   \n",
              "3                                    Bachelor/Honors   \n",
              "4      Bachelor of Science (BSc) in Computer Science   \n",
              "\n",
              "   experiencere_requirement     age_requirement  \\\n",
              "0           At least 1 year                 NaN   \n",
              "1        At least 5 year(s)                 NaN   \n",
              "2          At least 3 years                 NaN   \n",
              "3              1 to 3 years  Age 22 to 30 years   \n",
              "4          At least 4 years                 NaN   \n",
              "\n",
              "                                  responsibilities.1  \\\n",
              "0  Technical Support\\nTroubleshooting\\nCollaborat...   \n",
              "1  Machine Learning Leadership\\nCross-Functional ...   \n",
              "2  Trade Marketing Executive\\nBrand Visibility, S...   \n",
              "3  Apparel Sourcing\\nQuality Garment Sourcing\\nRe...   \n",
              "4  iOS Lifecycle\\nRequirement Analysis\\nNative Fr...   \n",
              "\n",
              "                                     skills_required matched_score shortlist  \n",
              "0                                                NaN      0.850000         0  \n",
              "1                                                NaN      0.750000         1  \n",
              "2  Brand Promotion\\nCampaign Management\\nField Su...      0.416667         0  \n",
              "3  Fast typing skill\\nIELTSInternet browsing & on...      0.760000         1  \n",
              "4  iOS\\niOS App Developer\\niOS Application Develo...      0.650000         1  \n",
              "\n",
              "[5 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 1. Load dataset\n",
        "# =====================================================\n",
        "\n",
        "DATA_PATH = \"./data/resume_data.csv\"   # change if needed\n",
        "\n",
        "df = pd.read_csv(DATA_PATH)\n",
        "print(\"Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "display(df.head())\n",
        "\n",
        "# Label column must exist\n",
        "LABEL_COL = \"shortlist\"\n",
        "df[LABEL_COL] = df[LABEL_COL].astype(int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Inferred gender_group counts (before filtering):\n",
            "gender_group\n",
            "female     3589\n",
            "male       3584\n",
            "unknown    2371\n",
            "Name: count, dtype: int64\n",
            "\n",
            "After filtering to only male/female rows:\n",
            "gender_group\n",
            "female    3589\n",
            "male      3584\n",
            "Name: count, dtype: int64\n",
            "New shape: (7173, 39)\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 2. Name column & gender inference\n",
        "# =====================================================\n",
        "\n",
        "NAME_COL = \"name\"\n",
        "\n",
        "detector = gender.Detector(case_sensitive=False)\n",
        "\n",
        "def infer_gender(name: str) -> str:\n",
        "    if pd.isna(name) or not isinstance(name, str) or name.strip() == \"\":\n",
        "        return \"unknown\"\n",
        "    first_name = name.strip().split()[0]\n",
        "    g = detector.get_gender(first_name)\n",
        "    if g in [\"male\", \"mostly_male\"]:\n",
        "        return \"male\"\n",
        "    elif g in [\"female\", \"mostly_female\"]:\n",
        "        return \"female\"\n",
        "    else:\n",
        "        return \"unknown\"\n",
        "\n",
        "df[\"gender_group\"] = df[NAME_COL].apply(infer_gender)\n",
        "print(\"\\nInferred gender_group counts (before filtering):\")\n",
        "print(df[\"gender_group\"].value_counts(dropna=False))\n",
        "\n",
        "# ðŸ”´ Keep only male / female, drop unknowns\n",
        "df = df[df[\"gender_group\"].isin([\"male\", \"female\"])].copy()\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(\"\\nAfter filtering to only male/female rows:\")\n",
        "print(df[\"gender_group\"].value_counts(dropna=False))\n",
        "print(\"New shape:\", df.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Sample combined_text:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>combined_text</th>\n",
              "      <th>shortlist</th>\n",
              "      <th>job_position_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...</td>\n",
              "      <td>0</td>\n",
              "      <td>Senior Software Engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['Software Development', 'Machine Learning', '...</td>\n",
              "      <td>0</td>\n",
              "      <td>Executive/ Senior Executive- Trade Marketing, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['accounts payables', 'accounts receivables', ...</td>\n",
              "      <td>1</td>\n",
              "      <td>Business Development Executive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['Analytical reasoning', 'Compliance testing k...</td>\n",
              "      <td>1</td>\n",
              "      <td>Senior iOS Engineer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['Machine Learning', 'Linear Regression', 'Rid...</td>\n",
              "      <td>0</td>\n",
              "      <td>Senior iOS Engineer</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                       combined_text  shortlist  \\\n",
              "0  ['Big Data', 'Hadoop', 'Hive', 'Python', 'Mapr...          0   \n",
              "1  ['Software Development', 'Machine Learning', '...          0   \n",
              "2  ['accounts payables', 'accounts receivables', ...          1   \n",
              "3  ['Analytical reasoning', 'Compliance testing k...          1   \n",
              "4  ['Machine Learning', 'Linear Regression', 'Rid...          0   \n",
              "\n",
              "                                   job_position_name  \n",
              "0                           Senior Software Engineer  \n",
              "1  Executive/ Senior Executive- Trade Marketing, ...  \n",
              "2                     Business Development Executive  \n",
              "3                                Senior iOS Engineer  \n",
              "4                                Senior iOS Engineer  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 3. Build combined resume text\n",
        "# =====================================================\n",
        "\n",
        "# You can adjust which columns to include\n",
        "text_cols = [\n",
        "    \"skills\",\n",
        "    \"responsibilities.1\",\n",
        "    \"educational_institution_name\",\n",
        "    \"degree_names\",\n",
        "    \"major_field_of_studies\",\n",
        "    \"educational_results\",\n",
        "    \"result_types\",\n",
        "]\n",
        "\n",
        "text_cols = [c for c in text_cols if c in df.columns]\n",
        "\n",
        "def combine_text_fields(row, cols):\n",
        "    parts = []\n",
        "    for c in cols:\n",
        "        val = row.get(c, \"\")\n",
        "        if pd.isna(val):\n",
        "            val = \"\"\n",
        "        parts.append(str(val))\n",
        "    return \" \".join(parts)\n",
        "\n",
        "df[\"combined_text\"] = df.apply(combine_text_fields, axis=1, cols=text_cols)\n",
        "df[\"combined_text\"] = df[\"combined_text\"].fillna(\"\").astype(str)\n",
        "\n",
        "print(\"\\nSample combined_text:\")\n",
        "display(df[[\"combined_text\", LABEL_COL, \"job_position_name\"]].head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Train size: 5738 Test size: 1435\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 4. Train / test split\n",
        "# =====================================================\n",
        "\n",
        "X = df[\"combined_text\"]\n",
        "y = df[LABEL_COL]\n",
        "\n",
        "X_train_text, X_test_text, y_train, y_test, train_gender, test_gender = train_test_split(\n",
        "    X,\n",
        "    y,\n",
        "    df[\"gender_group\"],\n",
        "    test_size=0.2,\n",
        "    random_state=RANDOM_STATE,\n",
        "    stratify=y,\n",
        ")\n",
        "\n",
        "print(\"\\nTrain size:\", len(X_train_text), \"Test size:\", len(X_test_text))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TF-IDF shape (train): (5738, 5000)\n",
            "TF-IDF shape (test) : (1435, 5000)\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 5. TF-IDF vectorization\n",
        "# =====================================================\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    max_features=5000,\n",
        "    ngram_range=(1, 2),\n",
        "    stop_words=\"english\",\n",
        ")\n",
        "\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train_text)\n",
        "X_test_tfidf  = vectorizer.transform(X_test_text)\n",
        "\n",
        "feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "print(\"TF-IDF shape (train):\", X_train_tfidf.shape)\n",
        "print(\"TF-IDF shape (test) :\", X_test_tfidf.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# =====================================================\n",
        "# 6. Helper: evaluation\n",
        "# =====================================================\n",
        "\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_score,\n",
        "    recall_score,\n",
        "    f1_score,\n",
        ")\n",
        "\n",
        "def evaluate_model(name, y_true, y_pred, verbose=True):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0   # focus metric from proposal\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"\\n===== {name} =====\")\n",
        "        print(\"Accuracy :\", acc)\n",
        "        print(\"Precision:\", prec)\n",
        "        print(\"Recall   :\", rec)\n",
        "        print(\"F1-score :\", f1)\n",
        "        print(\"FNR      :\", fnr)\n",
        "        print(\"\\nClassification report:\")\n",
        "        print(classification_report(y_true, y_pred, zero_division=0))\n",
        "        print(\"Confusion matrix (labels [0,1]):\")\n",
        "        print(cm)\n",
        "\n",
        "    return {\n",
        "        \"model\": name,\n",
        "        \"accuracy\": acc,\n",
        "        \"precision\": prec,\n",
        "        \"recall\": rec,\n",
        "        \"f1\": f1,\n",
        "        \"FNR\": fnr,\n",
        "        \"TP\": tp,\n",
        "        \"FP\": fp,\n",
        "        \"FN\": fn,\n",
        "        \"TN\": tn,\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "===== Linear SVM (C=1.0) =====\n",
            "Accuracy : 0.6306620209059234\n",
            "Precision: 0.63671875\n",
            "Recall   : 0.6608108108108108\n",
            "F1-score : 0.6485411140583555\n",
            "FNR      : 0.33918918918918917\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.62      0.60      0.61       695\n",
            "           1       0.64      0.66      0.65       740\n",
            "\n",
            "    accuracy                           0.63      1435\n",
            "   macro avg       0.63      0.63      0.63      1435\n",
            "weighted avg       0.63      0.63      0.63      1435\n",
            "\n",
            "Confusion matrix (labels [0,1]):\n",
            "[[416 279]\n",
            " [251 489]]\n",
            "\n",
            "===== RBF SVM (C=1.0) =====\n",
            "Accuracy : 0.6425087108013937\n",
            "Precision: 0.6396063960639606\n",
            "Recall   : 0.7027027027027027\n",
            "F1-score : 0.6696716033483581\n",
            "FNR      : 0.2972972972972973\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.65      0.58      0.61       695\n",
            "           1       0.64      0.70      0.67       740\n",
            "\n",
            "    accuracy                           0.64      1435\n",
            "   macro avg       0.64      0.64      0.64      1435\n",
            "weighted avg       0.64      0.64      0.64      1435\n",
            "\n",
            "Confusion matrix (labels [0,1]):\n",
            "[[402 293]\n",
            " [220 520]]\n",
            "\n",
            "===== Gaussian NB =====\n",
            "Accuracy : 0.5874564459930314\n",
            "Precision: 0.6326164874551972\n",
            "Recall   : 0.47702702702702704\n",
            "F1-score : 0.5439137134052389\n",
            "FNR      : 0.522972972972973\n",
            "\n",
            "Classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.56      0.71      0.62       695\n",
            "           1       0.63      0.48      0.54       740\n",
            "\n",
            "    accuracy                           0.59      1435\n",
            "   macro avg       0.60      0.59      0.58      1435\n",
            "weighted avg       0.60      0.59      0.58      1435\n",
            "\n",
            "Confusion matrix (labels [0,1]):\n",
            "[[490 205]\n",
            " [387 353]]\n",
            "\n",
            "===== Cross-validation: Linear SVM on training set =====\n",
            "CV F1 scores: [0.64795509 0.65837479 0.64191419 0.65245902 0.65127782]\n",
            "Mean F1: 0.6503961832629945 Std: 0.005414681705887695\n",
            "\n",
            "=== Benchmark comparison (test set) ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>accuracy</th>\n",
              "      <th>precision</th>\n",
              "      <th>recall</th>\n",
              "      <th>f1</th>\n",
              "      <th>FNR</th>\n",
              "      <th>TP</th>\n",
              "      <th>FP</th>\n",
              "      <th>FN</th>\n",
              "      <th>TN</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>model</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Linear SVM (C=1.0)</th>\n",
              "      <td>0.631</td>\n",
              "      <td>0.637</td>\n",
              "      <td>0.661</td>\n",
              "      <td>0.649</td>\n",
              "      <td>0.339</td>\n",
              "      <td>489</td>\n",
              "      <td>279</td>\n",
              "      <td>251</td>\n",
              "      <td>416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>RBF SVM (C=1.0)</th>\n",
              "      <td>0.643</td>\n",
              "      <td>0.640</td>\n",
              "      <td>0.703</td>\n",
              "      <td>0.670</td>\n",
              "      <td>0.297</td>\n",
              "      <td>520</td>\n",
              "      <td>293</td>\n",
              "      <td>220</td>\n",
              "      <td>402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Gaussian NB</th>\n",
              "      <td>0.587</td>\n",
              "      <td>0.633</td>\n",
              "      <td>0.477</td>\n",
              "      <td>0.544</td>\n",
              "      <td>0.523</td>\n",
              "      <td>353</td>\n",
              "      <td>205</td>\n",
              "      <td>387</td>\n",
              "      <td>490</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    accuracy  precision  recall     f1    FNR   TP   FP   FN  \\\n",
              "model                                                                          \n",
              "Linear SVM (C=1.0)     0.631      0.637   0.661  0.649  0.339  489  279  251   \n",
              "RBF SVM (C=1.0)        0.643      0.640   0.703  0.670  0.297  520  293  220   \n",
              "Gaussian NB            0.587      0.633   0.477  0.544  0.523  353  205  387   \n",
              "\n",
              "                     TN  \n",
              "model                    \n",
              "Linear SVM (C=1.0)  416  \n",
              "RBF SVM (C=1.0)     402  \n",
              "Gaussian NB         490  "
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 7. Train models\n",
        "# =====================================================\n",
        "\n",
        "metrics_summary = []\n",
        "\n",
        "# 7.1 Linear SVM\n",
        "linear_svm = LinearSVC(random_state=RANDOM_STATE, C=1.0)\n",
        "linear_svm.fit(X_train_tfidf, y_train)\n",
        "y_pred_linear = linear_svm.predict(X_test_tfidf)\n",
        "metrics_summary.append(\n",
        "    evaluate_model(\"Linear SVM (C=1.0)\", y_test, y_pred_linear, verbose=True)\n",
        ")\n",
        "\n",
        "# 7.2 RBF SVM\n",
        "rbf_svm = SVC(\n",
        "    kernel=\"rbf\",\n",
        "    C=1.0,\n",
        "    gamma=\"scale\",\n",
        "    probability=True,\n",
        "    random_state=RANDOM_STATE,\n",
        ")\n",
        "rbf_svm.fit(X_train_tfidf, y_train)\n",
        "y_pred_rbf = rbf_svm.predict(X_test_tfidf)\n",
        "metrics_summary.append(\n",
        "    evaluate_model(\"RBF SVM (C=1.0)\", y_test, y_pred_rbf, verbose=True)\n",
        ")\n",
        "\n",
        "# 7.3 Gaussian NB\n",
        "X_train_dense = X_train_tfidf.toarray()\n",
        "X_test_dense  = X_test_tfidf.toarray()\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train_dense, y_train)\n",
        "y_pred_gnb = gnb.predict(X_test_dense)\n",
        "metrics_summary.append(\n",
        "    evaluate_model(\"Gaussian NB\", y_test, y_pred_gnb, verbose=True)\n",
        ")\n",
        "\n",
        "# Cross-validation for Linear SVM\n",
        "print(\"\\n===== Cross-validation: Linear SVM on training set =====\")\n",
        "cv_scores = cross_val_score(\n",
        "    LinearSVC(random_state=RANDOM_STATE, C=1.0),\n",
        "    X_train_tfidf,\n",
        "    y_train,\n",
        "    cv=5,\n",
        "    scoring=\"f1\",\n",
        ")\n",
        "print(\"CV F1 scores:\", cv_scores)\n",
        "print(\"Mean F1:\", cv_scores.mean(), \"Std:\", cv_scores.std())\n",
        "\n",
        "# Neat comparison table\n",
        "metrics_df = pd.DataFrame(metrics_summary).set_index(\"model\").round(3)\n",
        "print(\"\\n=== Benchmark comparison (test set) ===\")\n",
        "display(metrics_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Top positive features (towards SHORTLIST = 1):\n",
            "preparation university    1.4078\n",
            "sql machine               1.0732\n",
            "knowledge university      1.0661\n",
            "management machine        0.8302\n",
            "maintenance university    0.8127\n",
            "seo university            0.7921\n",
            "metallurgy                0.7529\n",
            "tech metallurgy           0.7529\n",
            "analytics machine         0.7245\n",
            "sql html                  0.6411\n",
            "skills project            0.6399\n",
            "html                      0.6338\n",
            "intelligence data         0.6332\n",
            "program                   0.6168\n",
            "management                0.6095\n",
            "degree                    0.5821\n",
            "gpa                       0.5797\n",
            "leadership                0.5680\n",
            "analysis design           0.5593\n",
            "skill                     0.5559\n",
            "\n",
            "Top negative features (towards SHORTLIST = 0):\n",
            "analysis university       -1.0960\n",
            "learning university       -0.8646\n",
            "institute engineering     -0.8185\n",
            "verification university   -0.7813\n",
            "quality university        -0.7632\n",
            "integration university    -0.7625\n",
            "learning software         -0.7260\n",
            "analytics linear          -0.7203\n",
            "regression logistic       -0.7150\n",
            "management technical      -0.6774\n",
            "regression business       -0.6632\n",
            "jntu                      -0.6599\n",
            "mechanical mechanical     -0.6543\n",
            "tech chemical             -0.6319\n",
            "university university     -0.6311\n",
            "data analytics            -0.6211\n",
            "warsaw                    -0.6155\n",
            "university warsaw         -0.6155\n",
            "portland                  -0.6115\n",
            "portland state            -0.6115\n",
            "\n",
            "Example resume snippet:\n",
            "['GIS', 'lighting designs using Visual Professional', 'Access', 'Excel', 'Microsoft Office', 'Power Point'] Hardware & Network Installation\n",
            "Troubleshooting & Diagnostics\n",
            "User Training & Capacity Building\n",
            "Hardware Replacement\n",
            "Fault Repair & System Setup\n",
            "Software License & Account Management\n",
            "Backup Management\n",
            "System Updates & Maintenance\n",
            "Server & Storage Management\n",
            "Documentation & Technical Specific ...\n",
            "\n",
            "\n",
            "=== Explanation for prediction ===\n",
            "Predicted label   : 1\n",
            "Decision function : 0.34030228968756043\n",
            "\n",
            "Top contributing features:\n",
            "management                contribution: 0.0818\n",
            "gpa                       contribution: 0.0674\n",
            "degree                    contribution: 0.0431\n",
            "execution university      contribution: 0.0345\n",
            "bachelors                 contribution: -0.0335\n",
            "information               contribution: 0.0309\n",
            "point                     contribution: -0.0296\n",
            "professional              contribution: 0.0266\n",
            "repair                    contribution: -0.0262\n",
            "account                   contribution: -0.0261\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 8. Interpretability: Linear SVM coefficients\n",
        "# =====================================================\n",
        "\n",
        "coefs = linear_svm.coef_[0]\n",
        "\n",
        "def show_top_features(coefs, feature_names, top_k=20):\n",
        "    top_pos_idx = np.argsort(coefs)[-top_k:][::-1]\n",
        "    top_neg_idx = np.argsort(coefs)[:top_k]\n",
        "\n",
        "    print(\"\\nTop positive features (towards SHORTLIST = 1):\")\n",
        "    for idx in top_pos_idx:\n",
        "        print(f\"{feature_names[idx]:<25} {coefs[idx]:.4f}\")\n",
        "\n",
        "    print(\"\\nTop negative features (towards SHORTLIST = 0):\")\n",
        "    for idx in top_neg_idx:\n",
        "        print(f\"{feature_names[idx]:<25} {coefs[idx]:.4f}\")\n",
        "\n",
        "show_top_features(coefs, feature_names, top_k=20)\n",
        "\n",
        "# Example explanation function\n",
        "def explain_prediction(text, model, vectorizer, feature_names, coefs, top_k=10):\n",
        "    vec = vectorizer.transform([text])\n",
        "    decision = model.decision_function(vec)[0]\n",
        "    pred_label = model.predict(vec)[0]\n",
        "\n",
        "    vec_dense = vec.toarray()[0]\n",
        "    contributions = coefs * vec_dense\n",
        "\n",
        "    non_zero_indices = np.where(vec_dense != 0)[0]\n",
        "    non_zero_contribs = contributions[non_zero_indices]\n",
        "    non_zero_features = feature_names[non_zero_indices]\n",
        "\n",
        "    sorted_idx = np.argsort(np.abs(non_zero_contribs))[::-1][:top_k]\n",
        "\n",
        "    print(\"\\n=== Explanation for prediction ===\")\n",
        "    print(\"Predicted label   :\", pred_label)\n",
        "    print(\"Decision function :\", decision)\n",
        "    print(\"\\nTop contributing features:\")\n",
        "    for i in sorted_idx:\n",
        "        fname = non_zero_features[i]\n",
        "        contrib = non_zero_contribs[i]\n",
        "        print(f\"{fname:<25} contribution: {contrib:.4f}\")\n",
        "\n",
        "example_text = X_test_text.iloc[0]\n",
        "print(\"\\nExample resume snippet:\")\n",
        "print(example_text[:400], \"...\\n\")\n",
        "explain_prediction(\n",
        "    example_text,\n",
        "    model=linear_svm,\n",
        "    vectorizer=vectorizer,\n",
        "    feature_names=feature_names,\n",
        "    coefs=coefs,\n",
        "    top_k=10,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Fairness audit by gender_group (Linear SVM) ===\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>FPR</th>\n",
              "      <th>FNR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Support</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gender_group</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>female</th>\n",
              "      <td>0.406685</td>\n",
              "      <td>0.313984</td>\n",
              "      <td>0.640394</td>\n",
              "      <td>0.686016</td>\n",
              "      <td>0.662420</td>\n",
              "      <td>738</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>male</th>\n",
              "      <td>0.395833</td>\n",
              "      <td>0.365651</td>\n",
              "      <td>0.632597</td>\n",
              "      <td>0.634349</td>\n",
              "      <td>0.633472</td>\n",
              "      <td>697</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   FPR       FNR  Precision    Recall        F1  Support\n",
              "gender_group                                                            \n",
              "female        0.406685  0.313984   0.640394  0.686016  0.662420      738\n",
              "male          0.395833  0.365651   0.632597  0.634349  0.633472      697"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 9. Fairness by gender_group (Linear SVM)\n",
        "# =====================================================\n",
        "\n",
        "def group_metrics(y_true, y_pred):\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=[0, 1])\n",
        "    tn, fp, fn, tp = cm.ravel()\n",
        "    fpr = fp / (fp + tn) if (fp + tn) > 0 else 0.0\n",
        "    fnr = fn / (fn + tp) if (fn + tp) > 0 else 0.0\n",
        "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
        "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
        "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
        "    return {\n",
        "        \"FPR\": fpr,\n",
        "        \"FNR\": fnr,\n",
        "        \"Precision\": prec,\n",
        "        \"Recall\": rec,\n",
        "        \"F1\": f1,\n",
        "        \"Support\": len(y_true),\n",
        "    }\n",
        "\n",
        "test_df = pd.DataFrame({\n",
        "    \"text\": X_test_text.values,\n",
        "    \"y_true\": y_test.values,\n",
        "    \"y_pred\": y_pred_linear,\n",
        "    \"gender_group\": test_gender.values,\n",
        "})\n",
        "\n",
        "fairness_results = []\n",
        "for g in sorted(test_df[\"gender_group\"].unique()):\n",
        "    sub = test_df[test_df[\"gender_group\"] == g]\n",
        "    m = group_metrics(sub[\"y_true\"], sub[\"y_pred\"])\n",
        "    m[\"gender_group\"] = g\n",
        "    fairness_results.append(m)\n",
        "\n",
        "fairness_df = pd.DataFrame(fairness_results)\n",
        "print(\"\\n=== Fairness audit by gender_group (Linear SVM) ===\")\n",
        "display(fairness_df.set_index(\"gender_group\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Robustness results (raw):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>attack</th>\n",
              "      <th>flip_rate</th>\n",
              "      <th>flips</th>\n",
              "      <th>total</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Keyword stuffing</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>667</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Random typos</td>\n",
              "      <td>0.082459</td>\n",
              "      <td>55</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Template header/footer</td>\n",
              "      <td>0.188906</td>\n",
              "      <td>126</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Synonym replacement</td>\n",
              "      <td>0.001499</td>\n",
              "      <td>1</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Sentence shuffle</td>\n",
              "      <td>0.005997</td>\n",
              "      <td>4</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Adversarial insert</td>\n",
              "      <td>0.337331</td>\n",
              "      <td>225</td>\n",
              "      <td>667</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                   attack  flip_rate  flips  total\n",
              "0        Keyword stuffing   1.000000    667    667\n",
              "1            Random typos   0.082459     55    667\n",
              "2  Template header/footer   0.188906    126    667\n",
              "3     Synonym replacement   0.001499      1    667\n",
              "4        Sentence shuffle   0.005997      4    667\n",
              "5      Adversarial insert   0.337331    225    667"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved robustness report CSV: ./data/ml_pipeline_outputs/robustness_report.csv\n",
            "\n",
            "===== Robustness vs C (Linear SVM, keyword stuffing attack) =====\n",
            "\n",
            "Robustness vs C (table):\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>C</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>FNR</th>\n",
              "      <th>flip_rate_keyword_stuffing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.01</td>\n",
              "      <td>0.646690</td>\n",
              "      <td>0.263514</td>\n",
              "      <td>0.169550</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.10</td>\n",
              "      <td>0.639721</td>\n",
              "      <td>0.305405</td>\n",
              "      <td>0.987302</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.00</td>\n",
              "      <td>0.630662</td>\n",
              "      <td>0.339189</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10.00</td>\n",
              "      <td>0.629268</td>\n",
              "      <td>0.340541</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100.00</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.339189</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        C  accuracy       FNR  flip_rate_keyword_stuffing\n",
              "0    0.01  0.646690  0.263514                    0.169550\n",
              "1    0.10  0.639721  0.305405                    0.987302\n",
              "2    1.00  0.630662  0.339189                    1.000000\n",
              "3   10.00  0.629268  0.340541                    1.000000\n",
              "4  100.00  0.628571  0.339189                    1.000000"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved robustness-vs-C report CSV: ./data/ml_pipeline_outputs/robustness_vs_C.csv\n",
            "Saved robustness-vs-C plot: ./data/ml_pipeline_outputs/robustness_vs_C.png\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 10. Robustness attacks (Linear SVM)\n",
        "# =====================================================\n",
        "\n",
        "def attack_keyword_stuffing(text, keywords, repeat=3):\n",
        "    stuffing = \" \".join(list(keywords) * repeat)\n",
        "    return text + \" \" + stuffing\n",
        "\n",
        "def attack_random_typos(text, prob=0.02):\n",
        "    chars = list(text)\n",
        "    for i in range(len(chars)):\n",
        "        if np.random.rand() < prob and chars[i].isalpha():\n",
        "            chars.insert(i, chars[i])\n",
        "    return \"\".join(chars)\n",
        "\n",
        "def attack_template_header_footer(text):\n",
        "    header = \"Highly motivated candidate seeking challenging role. \"\n",
        "    footer = \" Proven track record of excellence across multiple domains.\"\n",
        "    return header + text + footer\n",
        "\n",
        "def attack_synonym_replacement(text):\n",
        "    mapping = {\n",
        "        \"good\": \"excellent\",\n",
        "        \"great\": \"outstanding\",\n",
        "        \"hardworking\": \"diligent\",\n",
        "        \"team\": \"group\",\n",
        "        \"leader\": \"lead\",\n",
        "    }\n",
        "    words = text.split()\n",
        "    new_words = [mapping.get(w.lower(), w) for w in words]\n",
        "    return \" \".join(new_words)\n",
        "\n",
        "def attack_sentence_shuffle(text):\n",
        "    sentences = [s.strip() for s in text.split(\".\") if s.strip() != \"\"]\n",
        "    if len(sentences) <= 1:\n",
        "        return text\n",
        "    np.random.shuffle(sentences)\n",
        "    return \". \".join(sentences) + \".\"\n",
        "\n",
        "def attack_adversarial_insert(text):\n",
        "    adv = (\n",
        "        \" consistently rated top performer with strong problem-solving, \"\n",
        "        \"stakeholder management, and leadership skills \"\n",
        "    )\n",
        "    mid = len(text) // 2\n",
        "    return text[:mid] + adv + text[mid:]\n",
        "\n",
        "def evaluate_attack(model, vectorizer, texts, labels, attack_fn, attack_name, **kwargs):\n",
        "    X_base = vectorizer.transform(texts)\n",
        "    base_pred = model.predict(X_base)\n",
        "\n",
        "    rejected_mask = (base_pred == 0)\n",
        "    rejected_texts = np.array(texts)[rejected_mask]\n",
        "\n",
        "    if len(rejected_texts) == 0:\n",
        "        return {\n",
        "            \"attack\": attack_name,\n",
        "            \"flip_rate\": 0.0,\n",
        "            \"flips\": 0,\n",
        "            \"total\": 0,\n",
        "        }\n",
        "\n",
        "    adv_texts = [attack_fn(t, **kwargs) for t in rejected_texts]\n",
        "    X_adv = vectorizer.transform(adv_texts)\n",
        "    adv_pred = model.predict(X_adv)\n",
        "\n",
        "    flips = np.sum(adv_pred == 1)\n",
        "    flip_rate = flips / len(adv_pred)\n",
        "\n",
        "    return {\n",
        "        \"attack\": attack_name,\n",
        "        \"flip_rate\": flip_rate,\n",
        "        \"flips\": flips,\n",
        "        \"total\": len(adv_pred),\n",
        "    }\n",
        "\n",
        "np.random.seed(42)\n",
        "top_keywords_for_attack = feature_names[np.argsort(coefs)[-10:][::-1]]\n",
        "\n",
        "attacks = [\n",
        "    (\"Keyword stuffing\",      attack_keyword_stuffing,      {\"keywords\": top_keywords_for_attack, \"repeat\": 3}),\n",
        "    (\"Random typos\",          attack_random_typos,          {\"prob\": 0.02}),\n",
        "    (\"Template header/footer\",attack_template_header_footer,{}),\n",
        "    (\"Synonym replacement\",   attack_synonym_replacement,   {}),\n",
        "    (\"Sentence shuffle\",      attack_sentence_shuffle,      {}),\n",
        "    (\"Adversarial insert\",    attack_adversarial_insert,    {}),\n",
        "]\n",
        "\n",
        "attack_results = []\n",
        "for name, fn, kw in attacks:\n",
        "    res = evaluate_attack(\n",
        "        model=linear_svm,\n",
        "        vectorizer=vectorizer,\n",
        "        texts=X_test_text.tolist(),\n",
        "        labels=y_test.tolist(),\n",
        "        attack_fn=fn,\n",
        "        attack_name=name,\n",
        "        **kw,\n",
        "    )\n",
        "    attack_results.append(res)\n",
        "\n",
        "attack_results_df = pd.DataFrame(attack_results)\n",
        "print(\"\\nRobustness results (raw):\")\n",
        "display(attack_results_df)\n",
        "\n",
        "# Nicely formatted robustness table\n",
        "robustness_table = attack_results_df.rename(columns={\n",
        "    \"attack\": \"attack\",\n",
        "    \"flip_rate\": \"flip_rate\",\n",
        "    \"flips\": \"flips\",\n",
        "    \"total\": \"total\",\n",
        "})\n",
        "\n",
        "# Save robustness CSV\n",
        "robustness_csv_path = os.path.join(output_dir, \"robustness_report.csv\")\n",
        "robustness_table.to_csv(robustness_csv_path, index=False)\n",
        "print(f\"\\nSaved robustness report CSV: {robustness_csv_path}\")\n",
        "\n",
        "Cs = [0.01, 0.1, 1.0, 10.0, 100.0]\n",
        "\n",
        "robustness_vs_C = []\n",
        "\n",
        "print(\"\\n===== Robustness vs C (Linear SVM, keyword stuffing attack) =====\")\n",
        "\n",
        "for C_val in Cs:\n",
        "    # Train Linear SVM with given C\n",
        "    svm_C = LinearSVC(random_state=RANDOM_STATE, C=C_val)\n",
        "    svm_C.fit(X_train_tfidf, y_train)\n",
        "\n",
        "    # Test-set performance\n",
        "    X_test_tfidf = vectorizer.transform(X_test_text)\n",
        "    y_pred_C = svm_C.predict(X_test_tfidf)\n",
        "    metrics_C = evaluate_model(\n",
        "        name=f\"Linear SVM (C={C_val})\",\n",
        "        y_true=y_test,\n",
        "        y_pred=y_pred_C,\n",
        "        verbose=False,   # already printed once for C=1.0\n",
        "    )\n",
        "\n",
        "    # For a fair comparison, reuse the same keyword list we used before\n",
        "    # (top_keywords_for_attack defined earlier from the baseline model)\n",
        "    kw_attack_res = evaluate_attack(\n",
        "        model=svm_C,\n",
        "        vectorizer=vectorizer,\n",
        "        texts=X_test_text.tolist(),\n",
        "        labels=y_test.tolist(),\n",
        "        attack_fn=attack_keyword_stuffing,\n",
        "        attack_name=\"Keyword stuffing\",\n",
        "        keywords=top_keywords_for_attack,\n",
        "        repeat=3,\n",
        "    )\n",
        "\n",
        "    robustness_vs_C.append({\n",
        "        \"C\": C_val,\n",
        "        \"accuracy\": metrics_C[\"accuracy\"],\n",
        "        \"FNR\": metrics_C[\"FNR\"],\n",
        "        \"flip_rate_keyword_stuffing\": kw_attack_res[\"flip_rate\"],\n",
        "    })\n",
        "\n",
        "robustness_vs_C_df = pd.DataFrame(robustness_vs_C)\n",
        "print(\"\\nRobustness vs C (table):\")\n",
        "display(robustness_vs_C_df)\n",
        "\n",
        "# Save CSV\n",
        "robustness_vs_C_csv = os.path.join(output_dir, \"robustness_vs_C.csv\")\n",
        "robustness_vs_C_df.to_csv(robustness_vs_C_csv, index=False)\n",
        "print(f\"Saved robustness-vs-C report CSV: {robustness_vs_C_csv}\")\n",
        "\n",
        "# Plot: C vs accuracy / FNR / flip rate\n",
        "fig, ax1 = plt.subplots(figsize=(7, 4))\n",
        "\n",
        "ax1.set_xscale(\"log\")\n",
        "ax1.plot(\n",
        "    robustness_vs_C_df[\"C\"],\n",
        "    robustness_vs_C_df[\"accuracy\"],\n",
        "    marker=\"o\",\n",
        "    label=\"Accuracy\"\n",
        ")\n",
        "ax1.plot(\n",
        "    robustness_vs_C_df[\"C\"],\n",
        "    robustness_vs_C_df[\"FNR\"],\n",
        "    marker=\"o\",\n",
        "    label=\"FNR\"\n",
        ")\n",
        "ax1.set_xlabel(\"C (log scale)\")\n",
        "ax1.set_ylabel(\"Accuracy / FNR\")\n",
        "ax1.set_title(\"Effect of C on performance and robustness (Linear SVM)\")\n",
        "\n",
        "ax2 = ax1.twinx()\n",
        "ax2.plot(\n",
        "    robustness_vs_C_df[\"C\"],\n",
        "    robustness_vs_C_df[\"flip_rate_keyword_stuffing\"],\n",
        "    marker=\"s\",\n",
        "    linestyle=\"--\",\n",
        "    label=\"Flip rate (keyword stuffing)\"\n",
        ")\n",
        "ax2.set_ylabel(\"Flip rate (keyword stuffing)\")\n",
        "\n",
        "# Build a combined legend\n",
        "lines1, labels1 = ax1.get_legend_handles_labels()\n",
        "lines2, labels2 = ax2.get_legend_handles_labels()\n",
        "ax1.legend(lines1 + lines2, labels1 + labels2, loc=\"best\")\n",
        "\n",
        "plt.tight_layout()\n",
        "robustness_vs_C_plot = os.path.join(output_dir, \"robustness_vs_C.png\")\n",
        "fig.savefig(robustness_vs_C_plot, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "print(f\"Saved robustness-vs-C plot: {robustness_vs_C_plot}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Requirement vs Shortlisting summary (overall) ===\n",
            "Total good candidates (by requirements/match): 2251\n",
            "Total weak candidates                         : 4922\n",
            "Good but rejected                             : 352\n",
            "Weak but shortlisted                          : 1802\n",
            "\n",
            "=== Requirement vs Shortlisting by gender_group ===\n",
            "              count  good_candidates  weak_candidates  good_but_rejected  \\\n",
            "gender_group                                                               \n",
            "female         3589             1129             2460                179   \n",
            "male           3584             1122             2462                173   \n",
            "\n",
            "              weak_but_shortlisted  avg_matched_score  avg_skill_overlap  \n",
            "gender_group                                                              \n",
            "female                         890           0.660678                0.0  \n",
            "male                           912           0.660177                0.0  \n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 11. Requirement-matching features & bias: good vs weak\n",
        "# =====================================================\n",
        "\n",
        "# Helpers already imported: re, np, pd\n",
        "\n",
        "def parse_skill_list(s):\n",
        "    if pd.isna(s):\n",
        "        return set()\n",
        "    tokens = re.split(r\"[,\\;/\\|]\", str(s).lower())\n",
        "    return set(t.strip() for t in tokens if t.strip() != \"\")\n",
        "\n",
        "def parse_years_from_text(s):\n",
        "    if pd.isna(s):\n",
        "        return np.nan\n",
        "    nums = re.findall(r\"\\d+\\.?\\d*\", str(s))\n",
        "    if not nums:\n",
        "        return np.nan\n",
        "    return float(nums[0])\n",
        "\n",
        "def degree_level(text):\n",
        "    if pd.isna(text):\n",
        "        return 0\n",
        "    t = str(text).lower()\n",
        "    if \"phd\" in t or \"doctor\" in t:\n",
        "        return 4\n",
        "    if \"master\" in t or \"m.tech\" in t or \"mtech\" in t or \"m.sc\" in t:\n",
        "        return 3\n",
        "    if \"bachelor\" in t or \"b.tech\" in t or \"btech\" in t or \"b.e\" in t or \"bsc\" in t:\n",
        "        return 2\n",
        "    if \"diploma\" in t:\n",
        "        return 1\n",
        "    return 0\n",
        "\n",
        "def parse_age_requirement(text):\n",
        "    if pd.isna(text):\n",
        "        return (np.nan, np.nan)\n",
        "    t = str(text).lower()\n",
        "    nums = re.findall(r\"\\d+\", t)\n",
        "    if (\"between\" in t or \"-\" in t) and len(nums) >= 2:\n",
        "        return (float(nums[0]), float(nums[1]))\n",
        "    if \"below\" in t or \"under\" in t or \"upto\" in t:\n",
        "        return (np.nan, float(nums[0])) if nums else (np.nan, np.nan)\n",
        "    if \"above\" in t or \"over\" in t:\n",
        "        return (float(nums[0]), np.nan) if nums else (np.nan, np.nan)\n",
        "    if len(nums) == 1:\n",
        "        return (float(nums[0]), np.nan)\n",
        "    return (np.nan, np.nan)\n",
        "\n",
        "# Skills overlap\n",
        "cand_skills = df[\"skills\"].fillna(\"\")\n",
        "req_skills  = df[\"skills_required\"].fillna(\"\")\n",
        "\n",
        "skill_overlap_count = []\n",
        "skill_overlap_ratio_req = []\n",
        "missing_required_skill_count = []\n",
        "skills_meet = []\n",
        "\n",
        "for cs, rs in zip(cand_skills, req_skills):\n",
        "    cs_set = parse_skill_list(cs)\n",
        "    rs_set = parse_skill_list(rs)\n",
        "    inter = cs_set & rs_set\n",
        "\n",
        "    overlap = len(inter)\n",
        "    missing = max(len(rs_set) - overlap, 0)\n",
        "    ratio_req = overlap / len(rs_set) if len(rs_set) > 0 else 0.0\n",
        "    meet_flag = 1 if missing == 0 and len(rs_set) > 0 else 0\n",
        "\n",
        "    skill_overlap_count.append(overlap)\n",
        "    skill_overlap_ratio_req.append(ratio_req)\n",
        "    missing_required_skill_count.append(missing)\n",
        "    skills_meet.append(meet_flag)\n",
        "\n",
        "df[\"skill_overlap_count\"] = skill_overlap_count\n",
        "df[\"skill_overlap_ratio_req\"] = skill_overlap_ratio_req\n",
        "df[\"missing_required_skill_count\"] = missing_required_skill_count\n",
        "df[\"skills_meet_all_required\"] = skills_meet\n",
        "\n",
        "# Experience\n",
        "cand_exp = pd.to_numeric(df[\"years_of_experience\"], errors=\"coerce\")\n",
        "req_exp_raw = df[\"experiencere_requirement\"].fillna(\"\")\n",
        "req_exp = req_exp_raw.apply(parse_years_from_text)\n",
        "\n",
        "df[\"candidate_experience_years\"] = cand_exp\n",
        "df[\"required_experience_years\"] = req_exp\n",
        "df[\"experience_gap\"] = df[\"candidate_experience_years\"] - df[\"required_experience_years\"]\n",
        "df[\"experience_meets\"] = (df[\"experience_gap\"] >= 0).astype(int)\n",
        "\n",
        "# Education\n",
        "cand_edu_text = (\n",
        "    df[\"educational_institution_name\"].fillna(\"\").astype(str)\n",
        "    + \" \" + df[\"degree_names\"].fillna(\"\").astype(str)\n",
        "    + \" \" + df[\"major_field_of_studies\"].fillna(\"\").astype(str)\n",
        "    + \" \" + df[\"educational_results\"].fillna(\"\").astype(str)\n",
        "    + \" \" + df[\"result_types\"].fillna(\"\").astype(str)\n",
        ")\n",
        "\n",
        "req_edu_text = df[\"educationaL_requirements\"].fillna(\"\")\n",
        "\n",
        "df[\"candidate_education_level\"] = cand_edu_text.apply(degree_level)\n",
        "df[\"required_education_level\"] = req_edu_text.apply(degree_level)\n",
        "df[\"education_gap\"] = df[\"candidate_education_level\"] - df[\"required_education_level\"]\n",
        "df[\"education_meets\"] = (df[\"education_gap\"] >= 0).astype(int)\n",
        "\n",
        "# Age requirement (job-level only)\n",
        "age_req_text = df[\"age_requirement\"].fillna(\"\")\n",
        "age_mins = []\n",
        "age_maxs = []\n",
        "for t in age_req_text:\n",
        "    mn, mx = parse_age_requirement(t)\n",
        "    age_mins.append(mn)\n",
        "    age_maxs.append(mx)\n",
        "\n",
        "df[\"age_min_required\"] = age_mins\n",
        "df[\"age_max_required\"] = age_maxs\n",
        "df[\"has_age_requirement\"] = (~df[\"age_requirement\"].isna()).astype(int)\n",
        "\n",
        "# Responsibilities similarity (simple Jaccard between skills & responsibilities)\n",
        "def jaccard_tokens(a, b):\n",
        "    if pd.isna(a) or pd.isna(b):\n",
        "        return 0.0\n",
        "    a_set = set(str(a).lower().split())\n",
        "    b_set = set(str(b).lower().split())\n",
        "    if not a_set or not b_set:\n",
        "        return 0.0\n",
        "    inter = len(a_set & b_set)\n",
        "    union = len(a_set | b_set)\n",
        "    return inter / union\n",
        "\n",
        "df[\"responsibility_match_jaccard\"] = [\n",
        "    jaccard_tokens(cand, job_req)\n",
        "    for cand, job_req in zip(\n",
        "        df[\"skills\"].fillna(\"\"), df[\"responsibilities.1\"].fillna(\"\")\n",
        "    )\n",
        "]\n",
        "\n",
        "df[\"matched_score\"] = pd.to_numeric(df[\"matched_score\"], errors=\"coerce\")\n",
        "\n",
        "# Good vs weak\n",
        "ms_valid = df[\"matched_score\"].dropna()\n",
        "if not ms_valid.empty:\n",
        "    ms_threshold = ms_valid.quantile(0.7)\n",
        "else:\n",
        "    ms_threshold = None\n",
        "\n",
        "df[\"high_matched_score\"] = (\n",
        "    (df[\"matched_score\"] >= ms_threshold).astype(int)\n",
        "    if ms_threshold is not None\n",
        "    else 0\n",
        ")\n",
        "\n",
        "df[\"meets_all_requirements\"] = (\n",
        "    (df[\"skills_meet_all_required\"] == 1)\n",
        "    & (df[\"experience_meets\"] == 1)\n",
        "    & (df[\"education_meets\"] == 1)\n",
        ").astype(int)\n",
        "\n",
        "df[\"good_candidate\"] = (\n",
        "    (df[\"meets_all_requirements\"] == 1) | (df[\"high_matched_score\"] == 1)\n",
        ").astype(int)\n",
        "df[\"weak_candidate\"] = 1 - df[\"good_candidate\"]\n",
        "\n",
        "df[\"is_shortlisted\"] = df[LABEL_COL].astype(int)\n",
        "df[\"good_but_rejected\"] = (\n",
        "    (df[\"good_candidate\"] == 1) & (df[\"is_shortlisted\"] == 0)\n",
        ").astype(int)\n",
        "df[\"weak_but_shortlisted\"] = (\n",
        "    (df[\"good_candidate\"] == 0) & (df[\"is_shortlisted\"] == 1)\n",
        ").astype(int)\n",
        "\n",
        "print(\"\\n=== Requirement vs Shortlisting summary (overall) ===\")\n",
        "total_good = df[\"good_candidate\"].sum()\n",
        "total_weak = df[\"weak_candidate\"].sum()\n",
        "print(f\"Total good candidates (by requirements/match): {total_good}\")\n",
        "print(f\"Total weak candidates                         : {total_weak}\")\n",
        "print(f\"Good but rejected                             : {df['good_but_rejected'].sum()}\")\n",
        "print(f\"Weak but shortlisted                          : {df['weak_but_shortlisted'].sum()}\")\n",
        "\n",
        "if \"gender_group\" in df.columns:\n",
        "    summary_by_gender = df.groupby(\"gender_group\").agg(\n",
        "        count=(\"is_shortlisted\", \"size\"),\n",
        "        good_candidates=(\"good_candidate\", \"sum\"),\n",
        "        weak_candidates=(\"weak_candidate\", \"sum\"),\n",
        "        good_but_rejected=(\"good_but_rejected\", \"sum\"),\n",
        "        weak_but_shortlisted=(\"weak_but_shortlisted\", \"sum\"),\n",
        "        avg_matched_score=(\"matched_score\", \"mean\"),\n",
        "        avg_skill_overlap=(\"skill_overlap_ratio_req\", \"mean\"),\n",
        "    )\n",
        "    print(\"\\n=== Requirement vs Shortlisting by gender_group ===\")\n",
        "    print(summary_by_gender)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved confusion matrix for Linear SVM (C=1.0): ./data/ml_pipeline_outputs/confusion_matrix_linear.png\n",
            "Saved confusion matrix for RBF SVM (C=1.0): ./data/ml_pipeline_outputs/confusion_matrix_rbf.png\n",
            "Saved confusion matrix for Gaussian NB: ./data/ml_pipeline_outputs/confusion_matrix_gaussian.png\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/fx/jncymvk542l1dbmsb4v40p_c0000gn/T/ipykernel_74260/2975014338.py:63: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  axes[0, 1].set_xticklabels(robustness_table[\"attack\"], rotation=25, ha=\"right\")\n",
            "/var/folders/fx/jncymvk542l1dbmsb4v40p_c0000gn/T/ipykernel_74260/2975014338.py:97: UserWarning: set_ticklabels() should only be used with a fixed number of ticks, i.e. after set_ticks() or using a FixedLocator.\n",
            "  ax.set_xticklabels(robustness_table[\"attack\"], rotation=25, ha=\"right\")\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saved dashboard: ./data/ml_pipeline_outputs/dashboard_summary.png\n",
            "Saved robustness plot: ./data/ml_pipeline_outputs/robustness_flip_rates_pretty.png\n",
            "Saved top features plot: ./data/ml_pipeline_outputs/top_features.png\n",
            "Saved confusion matrix: ./data/ml_pipeline_outputs/confusion_matrix_small.png\n",
            "\n",
            "Robustness results (table):\n",
            "                   attack  flip_rate  flips  total\n",
            "0        Keyword stuffing   1.000000    667    667\n",
            "1            Random typos   0.082459     55    667\n",
            "2  Template header/footer   0.188906    126    667\n",
            "3     Synonym replacement   0.001499      1    667\n",
            "4        Sentence shuffle   0.005997      4    667\n",
            "5      Adversarial insert   0.337331    225    667\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 12. Save some plots (dashboard + robustness + features + CM)\n",
        "# =====================================================\n",
        "\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "\n",
        "all_models_for_cm = [\n",
        "    (\"Linear SVM (C=1.0)\", y_pred_linear),\n",
        "    (\"RBF SVM (C=1.0)\",    y_pred_rbf),\n",
        "    (\"Gaussian NB\",        y_pred_gnb),\n",
        "]\n",
        "\n",
        "for name, y_pred in all_models_for_cm:\n",
        "    cm = confusion_matrix(y_test, y_pred, labels=[0, 1])\n",
        "    disp = ConfusionMatrixDisplay(cm, display_labels=[0, 1])\n",
        "    fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "    disp.plot(ax=ax, cmap=\"viridis\", colorbar=True)\n",
        "    ax.set_title(f\"Confusion Matrix ({name})\")\n",
        "    plt.tight_layout()\n",
        "    cm_file = os.path.join(\n",
        "        output_dir,\n",
        "        f\"confusion_matrix_{name.split()[0].lower().replace('(', '').replace(')', '')}.png\"\n",
        "    )\n",
        "    fig.savefig(cm_file, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    print(f\"Saved confusion matrix for {name}: {cm_file}\")\n",
        "\n",
        "# Top 15 features for plot\n",
        "top_k = 15\n",
        "top_idx = np.argsort(np.abs(coefs))[-top_k:]\n",
        "top_features = feature_names[top_idx]\n",
        "top_values = coefs[top_idx]\n",
        "order = np.argsort(top_values)\n",
        "top_features = top_features[order]\n",
        "top_values = top_values[order]\n",
        "\n",
        "cm_svc = confusion_matrix(y_test, y_pred_rbf, labels=[0, 1])\n",
        "\n",
        "# Fairness plot data\n",
        "fairness_plot = fairness_df.set_index(\"gender_group\")[[\"FPR\", \"FNR\"]]\n",
        "groups = fairness_plot.index.tolist()\n",
        "x = np.arange(len(groups))\n",
        "width = 0.35\n",
        "\n",
        "# Dashboard\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# (1,1) Fairness\n",
        "axes[0, 0].bar(x - width/2, fairness_plot[\"FPR\"].values, width, label=\"FPR\")\n",
        "axes[0, 0].bar(x + width/2, fairness_plot[\"FNR\"].values, width, label=\"FNR\")\n",
        "axes[0, 0].set_xticks(x)\n",
        "axes[0, 0].set_xticklabels(groups)\n",
        "axes[0, 0].set_ylabel(\"Rate\")\n",
        "axes[0, 0].set_title(\"Fairness by group (FPR & FNR)\")\n",
        "axes[0, 0].legend()\n",
        "\n",
        "# (1,2) Robustness\n",
        "axes[0, 1].bar(robustness_table[\"attack\"], robustness_table[\"flip_rate\"])\n",
        "for i, v in enumerate(robustness_table[\"flip_rate\"].values):\n",
        "    axes[0, 1].text(i, v + 0.0005, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "axes[0, 1].set_ylabel(\"Flip rate\")\n",
        "axes[0, 1].set_title(\"Robustness: Flip rates by attack\")\n",
        "axes[0, 1].set_xticklabels(robustness_table[\"attack\"], rotation=25, ha=\"right\")\n",
        "\n",
        "# (2,1) Top features\n",
        "axes[1, 0].barh(top_features, top_values)\n",
        "axes[1, 0].set_title(\"Top 15 model features (coef magnitude)\")\n",
        "axes[1, 0].set_xlabel(\"Coefficient\")\n",
        "axes[1, 0].invert_yaxis()\n",
        "\n",
        "# (2,2) Confusion matrix\n",
        "im = axes[1, 1].imshow(cm_svc, interpolation=\"nearest\")\n",
        "axes[1, 1].set_title(\"Confusion Matrix (RBF SVM)\")\n",
        "axes[1, 1].set_xlabel(\"Predicted\")\n",
        "axes[1, 1].set_ylabel(\"Actual\")\n",
        "axes[1, 1].set_xticks([0, 1])\n",
        "axes[1, 1].set_yticks([0, 1])\n",
        "axes[1, 1].set_xticklabels([0, 1])\n",
        "axes[1, 1].set_yticklabels([0, 1])\n",
        "for i in range(cm_svc.shape[0]):\n",
        "    for j in range(cm_svc.shape[1]):\n",
        "        axes[1, 1].text(j, i, str(cm_svc[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
        "fig.colorbar(im, ax=axes[1, 1])\n",
        "\n",
        "plt.tight_layout()\n",
        "dashboard_path = os.path.join(output_dir, \"dashboard_summary.png\")\n",
        "fig.savefig(dashboard_path, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "# Separate robustness plot\n",
        "fig, ax = plt.subplots(figsize=(7, 4))\n",
        "ax.bar(robustness_table[\"attack\"], robustness_table[\"flip_rate\"])\n",
        "for i, v in enumerate(robustness_table[\"flip_rate\"].values):\n",
        "    ax.text(i, v + 0.0005, f\"{v:.3f}\", ha=\"center\", va=\"bottom\", fontsize=8)\n",
        "ax.set_ylabel(\"Flip rate\")\n",
        "ax.set_title(\"Robustness: Flip rates by attack\")\n",
        "ax.set_xticklabels(robustness_table[\"attack\"], rotation=25, ha=\"right\")\n",
        "plt.tight_layout()\n",
        "robustness_plot_path = os.path.join(output_dir, \"robustness_flip_rates_pretty.png\")\n",
        "fig.savefig(robustness_plot_path, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "# Separate top features plot\n",
        "fig, ax = plt.subplots(figsize=(7, 5))\n",
        "ax.barh(top_features, top_values)\n",
        "ax.set_title(\"Top 15 model features (coef magnitude)\")\n",
        "ax.set_xlabel(\"Coefficient\")\n",
        "ax.invert_yaxis()\n",
        "plt.tight_layout()\n",
        "top_features_path = os.path.join(output_dir, \"top_features.png\")\n",
        "fig.savefig(top_features_path, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "# Separate confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(4.5, 4))\n",
        "im = ax.imshow(cm_svc, interpolation=\"nearest\")\n",
        "ax.set_title(\"Confusion Matrix (RBF SVM)\")\n",
        "ax.set_xlabel(\"Predicted\")\n",
        "ax.set_ylabel(\"Actual\")\n",
        "ax.set_xticks([0, 1])\n",
        "ax.set_yticks([0, 1])\n",
        "ax.set_xticklabels([0, 1])\n",
        "ax.set_yticklabels([0, 1])\n",
        "for i in range(cm_svc.shape[0]):\n",
        "    for j in range(cm_svc.shape[1]):\n",
        "        ax.text(j, i, str(cm_svc[i, j]), ha=\"center\", va=\"center\", color=\"black\")\n",
        "fig.colorbar(im)\n",
        "plt.tight_layout()\n",
        "cm_path = os.path.join(output_dir, \"confusion_matrix_small.png\")\n",
        "fig.savefig(cm_path, bbox_inches=\"tight\")\n",
        "plt.close(fig)\n",
        "\n",
        "print(f\"\\nSaved dashboard: {dashboard_path}\")\n",
        "print(f\"Saved robustness plot: {robustness_plot_path}\")\n",
        "print(f\"Saved top features plot: {top_features_path}\")\n",
        "print(f\"Saved confusion matrix: {cm_path}\")\n",
        "\n",
        "print(\"\\nRobustness results (table):\")\n",
        "print(robustness_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================= HUMAN-READABLE SUMMARY =================\n",
            "\n",
            "1) Overall performance of the three models on the held-out test set:\n",
            "   â€¢ Linear SVM (main, interpretable model):\n",
            "       - Accuracy: 63.1%\n",
            "       - Precision (shortlist=1): 63.7%\n",
            "       - Recall (shortlist=1):    66.1%\n",
            "       - F1 score:                0.649\n",
            "       - FNR (missed good ones):  33.9%\n",
            "\n",
            "   â€¢ RBF SVM (higher-capacity black-box benchmark):\n",
            "       - Accuracy: 64.3%, F1: 0.670, FNR: 29.7%\n",
            "   â€¢ Gaussian NB (simple probabilistic baseline):\n",
            "       - Accuracy: 58.7%, F1: 0.544, FNR: 52.3%\n",
            "\n",
            "2) Stability across data splits (cross-validation on Linear SVM):\n",
            "   â€¢ Average F1 across folds: 0.650 (Â± 0.005).\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 13. Human-readable global summary\n",
        "# =====================================================\n",
        "\n",
        "# Use metrics_df we created earlier\n",
        "lin = metrics_df.loc[\"Linear SVM (C=1.0)\"]\n",
        "rbf = metrics_df.loc[\"RBF SVM (C=1.0)\"]\n",
        "nb  = metrics_df.loc[\"Gaussian NB\"]\n",
        "\n",
        "print(\"\\n================= HUMAN-READABLE SUMMARY =================\\n\")\n",
        "\n",
        "print(\"1) Overall performance of the three models on the held-out test set:\")\n",
        "print(f\"   â€¢ Linear SVM (main, interpretable model):\")\n",
        "print(f\"       - Accuracy: {lin['accuracy']*100:.1f}%\")\n",
        "print(f\"       - Precision (shortlist=1): {lin['precision']*100:.1f}%\")\n",
        "print(f\"       - Recall (shortlist=1):    {lin['recall']*100:.1f}%\")\n",
        "print(f\"       - F1 score:                {lin['f1']:.3f}\")\n",
        "print(f\"       - FNR (missed good ones):  {lin['FNR']*100:.1f}%\\n\")\n",
        "\n",
        "print(f\"   â€¢ RBF SVM (higher-capacity black-box benchmark):\")\n",
        "print(f\"       - Accuracy: {rbf['accuracy']*100:.1f}%, F1: {rbf['f1']:.3f}, FNR: {rbf['FNR']*100:.1f}%\")\n",
        "\n",
        "print(f\"   â€¢ Gaussian NB (simple probabilistic baseline):\")\n",
        "print(f\"       - Accuracy: {nb['accuracy']*100:.1f}%, F1: {nb['f1']:.3f}, FNR: {nb['FNR']*100:.1f}%\\n\")\n",
        "\n",
        "mean_cv = cv_scores.mean()\n",
        "std_cv = cv_scores.std()\n",
        "print(\"2) Stability across data splits (cross-validation on Linear SVM):\")\n",
        "print(f\"   â€¢ Average F1 across folds: {mean_cv:.3f} (Â± {std_cv:.3f}).\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "================= CANDIDATE EXPLANATION =================\n",
            "\n",
            "Candidate: Joseph  (index 5940)\n",
            "Applied for: Manager- Human Resource Management (HRM)\n",
            "\n",
            "Inferred group (from name): male\n",
            "True label in dataset      : REJECT\n",
            "Model prediction           : REJECT\n",
            "Decision score (margin)    : -0.469\n",
            "\n",
            "Requirement satisfaction:\n",
            "  â€¢ Skills requirement met?       NO\n",
            "  â€¢ Experience requirement met?   NO\n",
            "  â€¢ Education requirement met?    NO\n",
            "  â€¢ Experience gap (cand - req):  -3.0 years\n",
            "  â€¢ Education gap (cand - req):   -1.0 level(s)\n",
            "  â€¢ Skill overlap (of required):  0.0%\n",
            "  â€¢ Missing required skills:      1\n",
            "  â€¢ Job age requirement:          \"Age 25 to 40 years\"\n",
            "\n",
            "Overall requirement-based verdict:\n",
            "  â†’ This candidate looks WEAK / borderline based on requirements / matched_score.\n",
            "  Matched score: 0.333\n",
            "\n",
            "How the model decided (from text):\n",
            "  The model chose to REJECT this candidate.\n",
            "\n",
            "Top words/phrases that helped:\n",
            "   + 'management' (towards shortlist, contribution 0.0569)\n",
            "   + 'engineering' (towards shortlist, contribution 0.0379)\n",
            "   + 'java' (towards shortlist, contribution 0.0360)\n",
            "   + 'performance' (towards shortlist, contribution 0.0323)\n",
            "   + 'orientation' (towards shortlist, contribution 0.0291)\n",
            "   + 'database' (towards shortlist, contribution 0.0221)\n",
            "   + 'employee' (towards shortlist, contribution 0.0169)\n",
            "   + 'event' (towards shortlist, contribution 0.0090)\n",
            "\n",
            "Top words/phrases that hurt:\n",
            "   - 'jntu' (towards reject, contribution -0.1354)\n",
            "   - 'learning software' (towards reject, contribution -0.1237)\n",
            "   - 'engineering python' (towards reject, contribution -0.0872)\n",
            "   - 'tech computer' (towards reject, contribution -0.0660)\n",
            "   - 'python java' (towards reject, contribution -0.0449)\n",
            "   - 'computer science' (towards reject, contribution -0.0376)\n",
            "   - 'python' (towards reject, contribution -0.0372)\n",
            "   - 'database management' (towards reject, contribution -0.0289)\n",
            "\n",
            "Consistency between requirements and decision:\n",
            "  â†’ Model decision roughly aligns with requirement-based assessment.\n",
            "\n",
            "Demographic context:\n",
            "   For group 'male':\n",
            "    â€¢ FPR (wrongly shortlisted) â‰ˆ 39.6%\n",
            "    â€¢ FNR (wrongly rejected)    â‰ˆ 36.6%\n",
            "    â€¢ Test-set size for group   : 697\n",
            "\n",
            "Plain-language takeaway:\n",
            "   Nothing dramatic: model and requirements more or less agree for this candidate.\n",
            "\n",
            "================= END CANDIDATE EXPLANATION =================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# =====================================================\n",
        "# 14. Single candidate explanation (requirements + model + bias)\n",
        "# =====================================================\n",
        "\n",
        "def explain_random_candidate(\n",
        "    model,\n",
        "    vectorizer,\n",
        "    feature_names,\n",
        "    coefs,\n",
        "    df,\n",
        "    X_text,\n",
        "    y_true,\n",
        "    gender_series,\n",
        "    fairness_df,\n",
        "    name_col=NAME_COL,\n",
        "    top_local_words=8,\n",
        "):\n",
        "    rand_pos = np.random.randint(0, len(X_text))\n",
        "    idx = X_text.index[rand_pos]\n",
        "\n",
        "    text = X_text.loc[idx]\n",
        "    true_label = int(y_true.loc[idx])\n",
        "    gender_group = gender_series.loc[idx]\n",
        "    row = df.loc[idx]\n",
        "\n",
        "    vec = vectorizer.transform([text])\n",
        "    decision = model.decision_function(vec)[0]\n",
        "    pred_label = int(model.predict(vec)[0])\n",
        "\n",
        "    vec_dense = vec.toarray()[0]\n",
        "    contributions = coefs * vec_dense\n",
        "    non_zero_idx = np.where(vec_dense != 0)[0]\n",
        "    non_zero_contribs = contributions[non_zero_idx]\n",
        "    non_zero_features = feature_names[non_zero_idx]\n",
        "\n",
        "    pos_mask = non_zero_contribs > 0\n",
        "    neg_mask = non_zero_contribs < 0\n",
        "    pos_features = non_zero_features[pos_mask]\n",
        "    pos_values = non_zero_contribs[pos_mask]\n",
        "    neg_features = non_zero_features[neg_mask]\n",
        "    neg_values = non_zero_contribs[neg_mask]\n",
        "\n",
        "    pos_order = np.argsort(-pos_values)[:top_local_words]\n",
        "    neg_order = np.argsort(neg_values)[:top_local_words]\n",
        "\n",
        "    top_help = list(zip(pos_features[pos_order], pos_values[pos_order]))\n",
        "    top_hurt = list(zip(neg_features[neg_order], neg_values[neg_order]))\n",
        "\n",
        "    skills_meet = int(row.get(\"skills_meet_all_required\", 0))\n",
        "    exp_meet = int(row.get(\"experience_meets\", 0))\n",
        "    edu_meet = int(row.get(\"education_meets\", 0))\n",
        "    good_candidate = int(row.get(\"good_candidate\", 0))\n",
        "    weak_candidate = int(row.get(\"weak_candidate\", 0))\n",
        "    matched_score = row.get(\"matched_score\", np.nan)\n",
        "\n",
        "    exp_gap = row.get(\"experience_gap\", np.nan)\n",
        "    edu_gap = row.get(\"education_gap\", np.nan)\n",
        "    skill_overlap = row.get(\"skill_overlap_ratio_req\", np.nan)\n",
        "    missing_skills = int(row.get(\"missing_required_skill_count\", 0))\n",
        "    age_req = row.get(\"age_requirement\", None)\n",
        "    has_age_req = int(row.get(\"has_age_requirement\", 0))\n",
        "\n",
        "    fairness_row = None\n",
        "    if gender_group in fairness_df[\"gender_group\"].values:\n",
        "        fairness_row = fairness_df[fairness_df[\"gender_group\"] == gender_group].iloc[0]\n",
        "\n",
        "    print(\"\\n================= CANDIDATE EXPLANATION =================\\n\")\n",
        "\n",
        "    name = row.get(name_col, \"Unknown\")\n",
        "    jp = row.get(\"job_position_name\", \"Unknown position\")\n",
        "\n",
        "    print(f\"Candidate: {name}  (index {idx})\")\n",
        "    print(f\"Applied for: {jp}\")\n",
        "    print(f\"Inferred group (from name): {gender_group}\")\n",
        "    print(f\"True label in dataset      : {'SHORTLIST' if true_label == 1 else 'REJECT'}\")\n",
        "    print(f\"Model prediction           : {'SHORTLIST' if pred_label == 1 else 'REJECT'}\")\n",
        "    print(f\"Decision score (margin)    : {decision:.3f}\\n\")\n",
        "\n",
        "    print(\"Requirement satisfaction:\")\n",
        "    print(f\"  â€¢ Skills requirement met?       {'YES' if skills_meet else 'NO'}\")\n",
        "    print(f\"  â€¢ Experience requirement met?   {'YES' if exp_meet else 'NO'}\")\n",
        "    print(f\"  â€¢ Education requirement met?    {'YES' if edu_meet else 'NO'}\")\n",
        "    if not np.isnan(exp_gap):\n",
        "        print(f\"  â€¢ Experience gap (cand - req):  {exp_gap:.1f} years\")\n",
        "    if not np.isnan(edu_gap):\n",
        "        print(f\"  â€¢ Education gap (cand - req):   {edu_gap:.1f} level(s)\")\n",
        "    if not np.isnan(skill_overlap):\n",
        "        print(f\"  â€¢ Skill overlap (of required):  {skill_overlap*100:.1f}%\")\n",
        "        print(f\"  â€¢ Missing required skills:      {missing_skills}\")\n",
        "    if has_age_req and isinstance(age_req, str):\n",
        "        print(f\"  â€¢ Job age requirement:          \\\"{age_req}\\\"\")\n",
        "    else:\n",
        "        print(\"  â€¢ Job has no explicit age restriction or it's unspecified.\")\n",
        "\n",
        "    print(\"\\nOverall requirement-based verdict:\")\n",
        "    if good_candidate:\n",
        "        print(\"  â†’ This candidate looks GOOD based on requirements / matched_score.\")\n",
        "    else:\n",
        "        print(\"  â†’ This candidate looks WEAK / borderline based on requirements / matched_score.\")\n",
        "    if not np.isnan(matched_score):\n",
        "        print(f\"  Matched score: {matched_score:.3f}\")\n",
        "\n",
        "    print(\"\\nHow the model decided (from text):\")\n",
        "    if pred_label == 1:\n",
        "        print(\"  The model chose to SHORTLIST this candidate.\")\n",
        "    else:\n",
        "        print(\"  The model chose to REJECT this candidate.\")\n",
        "\n",
        "    print(\"\\nTop words/phrases that helped:\")\n",
        "    if top_help:\n",
        "        for w, v in top_help:\n",
        "            print(f\"   + '{w}' (towards shortlist, contribution {v:.4f})\")\n",
        "    else:\n",
        "        print(\"   + No strong positive cues detected.\")\n",
        "\n",
        "    print(\"\\nTop words/phrases that hurt:\")\n",
        "    if top_hurt:\n",
        "        for w, v in top_hurt:\n",
        "            print(f\"   - '{w}' (towards reject, contribution {v:.4f})\")\n",
        "    else:\n",
        "        print(\"   - No strong negative cues detected.\")\n",
        "\n",
        "    print(\"\\nConsistency between requirements and decision:\")\n",
        "    if good_candidate and pred_label == 0:\n",
        "        print(\"  â†’ GOOD candidate but model REJECTED them.\")\n",
        "        print(\"     Possible reasons: resume text doesn't highlight strengths well,\")\n",
        "        print(\"     or the model/historical labels encode bias against similar profiles.\")\n",
        "    elif not good_candidate and pred_label == 1:\n",
        "        print(\"  â†’ WEAK candidate but model SHORTLISTED them.\")\n",
        "        print(\"     Possible reasons: buzzwords in text overpower actual requirement mismatch,\")\n",
        "        print(\"     or training data historically favoured similar weak profiles.\")\n",
        "    else:\n",
        "        print(\"  â†’ Model decision roughly aligns with requirement-based assessment.\")\n",
        "\n",
        "    print(\"\\nDemographic context:\")\n",
        "    if fairness_row is not None:\n",
        "        fpr = fairness_row[\"FPR\"] * 100\n",
        "        fnr = fairness_row[\"FNR\"] * 100\n",
        "        support = int(fairness_row[\"Support\"])\n",
        "        print(\n",
        "            f\"   For group '{gender_group}':\\n\"\n",
        "            f\"    â€¢ FPR (wrongly shortlisted) â‰ˆ {fpr:.1f}%\\n\"\n",
        "            f\"    â€¢ FNR (wrongly rejected)    â‰ˆ {fnr:.1f}%\\n\"\n",
        "            f\"    â€¢ Test-set size for group   : {support}\"\n",
        "        )\n",
        "    else:\n",
        "        print(\"   No fairness statistics available for this group.\")\n",
        "\n",
        "    print(\"\\nPlain-language takeaway:\")\n",
        "    if good_candidate and pred_label == 0:\n",
        "        print(\"   Strong by requirements, but still rejected â†’ classic unfair-looking case.\")\n",
        "    elif not good_candidate and pred_label == 1:\n",
        "        print(\"   Weak by requirements, but still shortlisted â†’ model might be overfitting to buzzwords.\")\n",
        "    else:\n",
        "        print(\"   Nothing dramatic: model and requirements more or less agree for this candidate.\")\n",
        "\n",
        "    print(\"\\n================= END CANDIDATE EXPLANATION =================\\n\")\n",
        "\n",
        "\n",
        "# Run this to see one random candidate explanation\n",
        "explain_random_candidate(\n",
        "    model=linear_svm,\n",
        "    vectorizer=vectorizer,\n",
        "    feature_names=feature_names,\n",
        "    coefs=coefs,\n",
        "    df=df,\n",
        "    X_text=X_test_text,\n",
        "    y_true=y_test,\n",
        "    gender_series=test_gender,\n",
        "    fairness_df=fairness_df,\n",
        "    name_col=NAME_COL,\n",
        ")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "mlpro (3.13.9)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
